#author: Alex Sun
#date: 08102021
#purpose: gather other 5day data
#09172021, revise to add runoff data
#09182021, add basin averaging capabilities
#09262021, add ERA5 SM and gleam ET
#09292021, tacc doesn't like chunked array, disable it if possible
#03252022, adapt this for cvq-vae project
#04102022, added loading functions for ERA5 watervapor and GPM
#04152022, added loading functions for MERRA-2 SM
#06172023, add REGEN data loading capability
#===================================================================================

import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
import os, glob,sys
import pandas as pd
from scipy.stats import gumbel_r
import xscale.signal.fitting as xfit
from datetime import datetime 
from myutils import getGraceRoot
from regen import loadREGEN
from get_gpcpdata import loadGPCP

def filterClimateData(da,deTrend=True, returnSeasonal=False):
    """Filter climate data
    da, unfiltered DataArray
    deTrend, if True, fit and remove linear trend
    Returns
    -------
    interannual, seasonal, trend: interannual, seasonal, and linear trend
    """
    oldtimes = da['time'].values
    #assuming data product since the beginning of the dataset
    da.coords['time'] = np.arange(1,len(da['time'])+1).astype(np.int64)
    #print (oldtimes)
    #print (da.coords['time'])

    da = da.chunk('auto')
    if deTrend:
        #detrend
        trend = xfit.trend(da,dim='time',type='linear')
        da = da-trend        
    #remove seasonal
    modes = xfit.sinfit(da, dim='time', periods=[182.625,365.25],unit='d')
    #modes = modes.chunk(chunks={'lat': 90, 'lon': 90, 'time': 1})
    seasonal = xfit.sinval(modes=modes, coord=da.time)

    interannual = da - seasonal
    interannual.coords['time'] = oldtimes
    #as0929, remove chunk array
    interannual = xr.DataArray(interannual.values, 
                dims=interannual.dims, 
                coords=interannual.coords,
                attrs=interannual.attrs,)
    if returnSeasonal:
        return interannual, seasonal
    else:
        return interannual

#currently this is for conus only
def loadDataCollection(rootDir, varname, outncfile, reLoad=False, isPlot=False):
    """Load ERA5 data from daily grib files for each year and generate nc file
        (generated by era5aggregate.py from hourly files)
    Param
    ------
    rootDir, root directory of all precip daily files

    Returns
    -------
    ds, combined dataset from 2000 to 2020
    """    
    if reLoad:
        #get sorted precip daily netcdf files
        files = os.path.join(rootDir, 'daily_2???.nc')
        dailyFiles = sorted(glob.glob(files))
        bigDS=[]
        
        for item in dailyFiles:
            print (item)
            ds = xr.open_dataset(item)
            if varname=='precip':
                #get total precip as dataarray
                da = ds.tp
            elif varname=='airtemp':
                da = ds.t2m
            elif varname=='gpm':
                da = ds.tp # is this right?
            elif varname=='runoff':
                da = ds.ro
            elif varname=="sm":
                da = ds['__xarray_dataarray_variable__']
            elif varname=='gleam':
                da = ds.E

            if isPlot:
                #get the first day of total precip
                #I validated the result using google earth engine
                da1 = da.isel(time=[0]).squeeze()

                fig,ax=plt.subplots(1,1)
                ax.imshow(da1.values)
                plt.savefig('testera5.png')
                plt.close()
            bigDS.append(da)
        
        combined = xr.concat(bigDS, dim='time')
        if varname=='sm':
            da = xr.DataArray(combined.values,name="sm",coords=combined.coords,dims=combined.dims)
            da.to_netcdf(outncfile)
        else:
            combined.to_netcdf(outncfile)
    
    return xr.open_dataset(outncfile)
    
def loadERA(varname, rootDataDir, startYear,endYear):
    """Load ERA data
    """
    if varname == 'precip':
        precipdailyncfile = os.path.join(rootDataDir,'data/era5_precip_2002_2022_daily.nc')
        #precipdailyncfile = os.path.join(rootDataDir,'data/era5_precip_2002_2022_daily_025.nc')
        ds = xr.open_dataset(precipdailyncfile)
        da = ds['tp'].sel(time=slice('{0:4d}-01-01'.format(startYear), '{0:4d}-12-31'.format(endYear)))
    elif varname == "airtemp":
        airtempdailyncfile = os.path.join(rootDataDir,'data/era5_airtemp_2002_2020_daily.nc')
        ds = xr.open_dataset(airtempdailyncfile)
        da = ds['t2m'].sel(time=slice('{0:4d}-01-01'.format(startYear), '{0:4d}-12-31'.format(endYear)))
    elif varname == "sst":
        sstdailyncfile = os.path.join(rootDataDir,'data/era5_sst_2002_2020_daily.nc')
        ds = xr.open_dataset(sstdailyncfile)
        da = ds['sea_surface_temperature'].sel(time=slice('{0:4d}-01-01'.format(startYear), '{0:4d}-12-31'.format(endYear)))

    return da

def loadGPM(rootdir,startYear,endYear):
    """Load global GPM (this is resampled to 1 deg from the original 0.1 deg) [cm]
    """
    gpmncfile = os.path.join(rootdir, 'gpm_v6_2002_2020_daily.nc')
    ds = xr.open_dataset(gpmncfile)
    da = ds['precipitationCal'].sel(time=slice('{0:4d}-01-01'.format(startYear), '{0:4d}-12-31'.format(endYear)))
    return da

def precipLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020):
    #subsetting
    lat0,lon0,lat1,lon1 = regionExtents
    latslice = slice(lat0,lat1)
    lonslice = slice(lon0,lon1)       
    print ('Use ', source, ' as precipitation data')

    if source=='ERA5':
        rootDataDir = getGraceRoot()
        da = loadERA('precip',rootDataDir,startYear,endYear)
        #ERA lon is from 0 360
        #shift from 0, 360 to -179,180
        #assume one degree data        
        da.coords['longitude'] = (da.coords['longitude'] + 180) % 360 - 180
        da = da.sortby(da.longitude)
        da = da.sortby(da.latitude)
        da = da.sel(latitude=latslice,longitude=lonslice)
        #!!!! convert from m/day to cm/d 
        print ('increase ERA5 precip 100 times')
        da = da*100.0
    elif source=='GPM':
        rootDataDir = os.path.join(getGraceRoot(), 'data/gpm')
        da = loadGPM(rootDataDir,startYear,endYear)
        da = da.sortby(da.lat)
        da = da.sel(lat=latslice,lon=lonslice)        
    
    elif source=='REGEN':
        rootDataDir = os.path.join(getGraceRoot(), 'data/regen')
        da = loadREGEN(rootDataDir)
        da = da.sortby(da.lat)
        da = da.sel(lat=latslice,lon=lonslice)        

    elif source=='GPCP':
        rootDataDir = os.path.join(getGraceRoot(), 'data/gpcp')
        da = loadGPCP(rootDataDir)
        da = da.sortby(da.lat)
        da = da.sel(lat=latslice,lon=lonslice)      
    
    return da

def airtempLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020):
    if source=='ERA5':
        rootDataDir = getGraceRoot()
        #get data array
        da = loadERA('airtemp', rootDataDir,startYear,endYear)

        #ERA lon is from 0 360
        #shift from 0, 360 to -179,180        
        da.coords['longitude'] = (da.coords['longitude'] + 180) % 360 - 180
        da = da.sortby(da.longitude)
        da = da.sortby(da.latitude)
        #rename the coords
        da = da.rename({'longitude':'lon', 'latitude':'lat'})    
    
        ##!!!!!note I accidentally used sum() instead of mean() when resampling the data 
        #so need to divide by 24 to get daily mean values
        print ('get mean air temp')
        da = da / 24.0
    else:
        raise Exception('invalid data source')
    lat0,lon0,lat1,lon1 = regionExtents
    latslice = slice(lat0,lat1)
    lonslice = slice(lon0,lon1)           
    da = da.sel(lat=latslice,lon=lonslice)

    return da    

def sstLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020):
    if source=='ERA5':
        rootDataDir = getGraceRoot()
        #get data array
        da = loadERA('sst', rootDataDir,startYear,endYear)

        #ERA lon is from 0 360
        #shift from 0, 360 to -179,180        
        da.coords['longitude'] = (da.coords['longitude'] + 180) % 360 - 180
        da = da.sortby(da.longitude)
        da = da.sortby(da.latitude)
        #rename the coords
        da = da.rename({'longitude':'lon', 'latitude':'lat'})    
    
        ##!!!!!note I accidentally used sum() instead of mean() when resampling the data 
        #so need to divide by 24 to get daily mean values
        print ('get sst')
    else:
        raise Exception('invalid data source')
    lat0,lon0,lat1,lon1 = regionExtents
    latslice = slice(lat0,lat1)
    lonslice = slice(lon0,lon1)           
    da = da.sel(lat=latslice,lon=lonslice)

    return da    

def runoffLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020,reLoad=False):
    if source=='ERA5':
        rootDataDir = getGraceRoot()
        ds = loadERA('runoff', rootDataDir,startYear,endYear,reLoad=reLoad)
    
    #subsetting
    da = ds.ro
    da = da.sortby(da.latitude)
    lat0,lon0,lat1,lon1 = regionExtents
    latslice = slice(lat0,lat1)
    lonslice = slice(lon0,lon1)       
    
    da = da.sel(latitude=latslice,longitude=lonslice)

    return da    

def smLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020,reLoad=False):
    if source=='ERA5':
        rootDataDir = getGraceRoot()
        ds = loadERA('sm', rootDataDir,startYear,endYear,reLoad=reLoad)
    
    #subsetting
    da = ds.sm
    da = da.sortby(da.latitude)
    lat0,lon0,lat1,lon1 = regionExtents
    latslice = slice(lat0,lat1)
    lonslice = slice(lon0,lon1)       
    
    da = da.sel(latitude=latslice,longitude=lonslice)

    return da    

def getR5d(da,RT=5,da5d=None,mask=None):
    """Get R_5d series

    """
    if 'longitude' in da.dims:
        da = da.rename({'longitude':'lon', 'latitude':'lat'})
    quantile = 1.0 -1.0/RT
    if not mask is None:
        #apply mask to da and da5d
        bigarr = da.values
        bigarr = np.einsum('kij,ij->kij',bigarr,mask)
        da = xr.DataArray(bigarr,coords=da.coords,dims=da.dims)
        
        bigarr = da5d.values
        bigarr = np.einsum('kij,ij->kij', bigarr,mask)
        da5d = xr.DataArray(bigarr,coords=da5d.coords,dims=da5d.dims)

    #get rolling sum
    R5dDF = da.rolling(time=5, center=True,min_periods=1).sum()
    #get annual maxima
    annualMaxima = R5dDF.groupby("time.year").max().values
    print (annualMaxima.shape)
    #fit gumbel for each cell
    _, nRow, nCol = annualMaxima.shape
    qarr = np.zeros((nRow,nCol))
    for i in range(nRow):
        for j in range(nCol):        
            loc,scale = gumbel_r.fit(annualMaxima[:,i,j])
            qarr[i,j] = gumbel_r.ppf(quantile, loc,scale)

    if not da5d is None:
        nT,nRow,nCol = da5d.shape
        bigarr = da5d.values
        anomalyArr = np.zeros((nT,nRow,nCol))
        for i in range(nRow):
            for j in range(nCol):
                print (qarr[i,j])
                anomalyArr[:,i,j][bigarr[:,i,j]>qarr[i,j]]=1
        nAnomaly = np.sum(anomalyArr, axis=(1,2))
        daAnomaly = xr.DataArray(anomalyArr,dims=da5d.dims,coords=da5d.coords)
        """"
        months = [891,1111, 1124, 1125, 1128] 
        fig,ax = plt.subplots(len(months),2,figsize=(16,8))
        for ix,im in enumerate(months):
            print (da5d.isel(time=im).min())
            da5d.isel(time=im).plot.imshow(ax=ax[ix,0],vmin=0.0)
            daAnomaly.isel(time=im).plot.imshow(ax=ax[ix,1])
        plt.tight_layout(h_pad=0.1)
        plt.savefig('numofanomaly.png')
        plt.close()

        plt.figure()
        plt.hist(nAnomaly,bins=20)
        plt.savefig('numofanomaly.png')
        plt.close()
        """
        return daAnomaly
    else:
        return qarr

def resampleDaily(da, ds_tws:pd.Series=None, rule:str='sum', 
        returnArray:bool=True):
    """Resample daily data series to match CSR5d periods
    Param
    -----
    ds, data series to be downsampled
    rule, either sum or mean
    returnArray, True to return numpy and time index, False, return pd.Series

    """
    #start time of csr5d 2002-04-07
    #end time of csr5d 2020-09-15
    #note: use the center of each 5 day period to do aggregation
    #so 4/7 represents aggregation from 4/5 to 4/9
    #
    if 'longitude' in da.dims:
        da = da.rename({'longitude':'lon', 'latitude':'lat'})
    startTime = '2002-04-05'
    endTime = '2020-09-17'

    tt =pd.to_datetime(da['time'].data)        
    #convert da to dataframe
    bigarr = da.to_numpy()
    nT,nCol,nRow = bigarr.shape
    
    bigarr = bigarr.reshape(nT,nCol*nRow)
    df = pd.DataFrame(bigarr, index=tt)
    
    mask = (tt >= pd.to_datetime(startTime)) & (tt<= pd.to_datetime(endTime))
    masked = df[mask]

    #this assumes there is not gap in the input series (tws)
    if rule == 'sum':
        dfNew = masked.resample('5d').sum()
    elif rule== 'mean':
        dfNew = masked.resample('5d').mean()
    dfNew.index = dfNew.index+pd.Timedelta(2, unit='day')
    #convert to dataarray
    bigarr = dfNew.values.reshape(dfNew.shape[0],nCol,nRow)

    daNew = xr.DataArray(bigarr,dims=da.dims,
        coords=dict(time=dfNew.index,lon=da.lon,lat=da.lat)
    )
    
    return daNew

def getPrecipData(regionExtents,source, aggregateTo5d=True,startYear=2002, endYear=2020):
    """Get 5d data
    aggregateTo5d: aggregate data to match with csr5d
    asun06192023, add extra parameters startYear & endYear
    """
    assert (source in ['ERA5', 'GPM', 'REGEN', 'GPCP'])
    daPrecip = precipLoader(regionExtents,source=source,startYear=startYear,endYear=endYear)  
    if aggregateTo5d:
        daPrecip = resampleDaily(daPrecip,rule='sum')    
    else:
        if 'longitude' in daPrecip.dims:
            daPrecip = daPrecip.rename({'longitude':'lon', 'latitude':'lat'})
    #swap the order of coords
    daPrecip = daPrecip.transpose("time","lat","lon")
    return daPrecip

def getSWEData(regionExtents,source, aggregateTo5d=True,startYear=2002, endYear=2020):
    """Get 5d data
    aggregateTo5d: aggregate data to match with csr5d    
    """
    assert (source in ['era5'])
    rootDataDir = getGraceRoot()
    swe_ncfile = os.path.join(rootDataDir, 'data/era5_swe_2002_2022_daily.nc')

    daSWE = xr.open_dataset(swe_ncfile)['sd']
    daSWE = daSWE.sel(time=slice('{0:4d}/01/01'.format(startYear), '{0:4d}/12/31'.format(endYear)))    

    if aggregateTo5d:
        daSWE = resampleDaily(daSWE,rule='mean')    

    if 'longitude' in daSWE.dims:
        daSWE = daSWE.rename({'longitude':'lon', 'latitude':'lat'})
    #swap the order of coords
    daSWE = daSWE.transpose("time","lat","lon")
    #convert to cm from m swe
    print ('convert from m to cm')
    daSWE = daSWE*100.0
    return daSWE


def getWaterVaporData(regionExtents, startYear=2002, endYear=2020):
    """water vapor data
    """
    rootDataDir = getGraceRoot()
    watervaporncfile = os.path.join(rootDataDir, 'data/era5/watervapor/era5_watervapor_2002_2020_daily.nc')
    ds = xr.open_dataset(watervaporncfile)
    #rename the coords
    if 'longitude' in ds.dims:
        ds = ds.rename({'longitude':'lon', 'latitude':'lat'})
    #change from 0, 360 to -180 to 180
    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180 
    ds = ds.sel(time=slice('{0:4d}/01/01'.format(startYear), '{0:4d}/12/31'.format(endYear)))    
    da_u = ds['p88.162']
    da_v = ds['p89.162']
    da_u = da_u.transpose("time","lat","lon")
    da_v = da_v.transpose("time","lat","lon")
    return da_u, da_v

def getMERRA2SoilMoistureData(regionExtents, startYear=2002, endYear=2020):
    """obtain soil moisture data
    """
    rootDataDir = getGraceRoot()
    ncfile = os.path.join(rootDataDir, 'data/merra2/merra2_sm_2002_2020_daily.nc')
    ds = xr.open_dataset(ncfile)

    ds = ds.sel(time=slice('{0:4d}/01/01'.format(startYear), '{0:4d}/12/31'.format(endYear)))    
    da = ds['RZMC']
    return da

def getGLEAMData(regionExtents, startYear=2002, endYear=2020):
    """obtain gleam data
    """
    rootDataDir = getGraceRoot()
    ncfile = os.path.join(rootDataDir, 'data/gleam35_daily_global20022020.nc')
    ds = xr.open_dataset(ncfile)

    ds = ds.sel(time=slice('{0:4d}/01/01'.format(startYear), '{0:4d}/12/31'.format(endYear)))    
    da = ds.E #this is already in cm/d
    da = da.transpose('time','lat','lon')
    return da

def getAirTempData(regionExtents,aggregateTo5d=True):
    """Get 5d data 
    aggregateTo5d: aggregate data to match with csr5d
    """
    daTemp = airtempLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020)  
    if aggregateTo5d:
        daTemp = resampleDaily(daTemp,rule='mean')    

    daTemp = daTemp.transpose("time","lat","lon")
    #
    return daTemp

def getSSTData(regionExtents,aggregateTo5d=True):
    """Get 5d data 
    aggregateTo5d: aggregate data to match with csr5d
    """
    daTemp = sstLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020)  
    if aggregateTo5d:
        daTemp = resampleDaily(daTemp,rule='mean')    

    daTemp = daTemp.transpose("time","lat","lon")
    #
    return daTemp


def getRunoffData(regionExtents,aggregateTo5d=True,reLoad=False):
    """Get 5d era5 runoff 
    aggregateTo5d: aggregate data to match with csr5d
    """
    daRO = runoffLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020,
            reLoad=reLoad)  
    if aggregateTo5d:
        daRO = resampleDaily(daRO,rule='sum')   

    #swap the order of coords
    if 'longitude' in daRO.dims:
        daRO = daRO.rename({'longitude':'lon', 'latitude':'lat'})

    daRO = daRO.transpose("time","lat","lon")
    return daRO

def getSMData(regionExtents,aggregateTo5d=True,reLoad=False):
    """Get 5d era5 soil moisture 
    aggregateTo5d: aggregate data to match with csr5d [this is for conus only]
    """
    daSM = smLoader(regionExtents,source='ERA5',startYear=2002,endYear=2020,
            reLoad=reLoad)  
    if aggregateTo5d:
        daSM = resampleDaily(daSM,rule='mean')   

    #swap the order of coords
    if 'longitude' in daSM.dims:
        daSM = daSM.rename({'longitude':'lon', 'latitude':'lat'})

    daSM = daSM.transpose("time","lat","lon")
    return daSM

def main():
    #llcrnrlon =-108.985-1.0; llcrnrlat=24.498131-1.0    
    llcrnrlon =-109; llcrnrlat=24 #the bound of downloaded ERA5 data is 24 to 50
    blocksize = 64
    cellsize  = 0.25
    lon0 = llcrnrlon; lon1 = lon0+(blocksize-1)*cellsize
    lat0 = llcrnrlat; lat1 = lat0+(blocksize-1)*cellsize
    region = (lat0,lon0,lat1,lon1)

    daPrecip = getPrecipData(region, aggregateTo5d=True)
    daTemp   = getAirTempData(region, aggregateTo5d=True)
    daSurfaceRunoff = getRunoffData(region, aggregateTo5d=True)
    
    print (daPrecip.shape, daTemp.shape, daSurfaceRunoff.shape)

    #daAnomaly = getR5d(daPrecip,da5d=daPrecip5d)
    #print (daAnomaly.shape)
    
    return 
    daTemp5d = resampleDaily(daTemp,rule='mean')
    print (daPrecip.shape) #->(7671, 87, 81)
    print (daPrecip.coords)
    print (daTemp.shape) #->(7671, 87, 81)
    print (daTemp.coords)

if __name__ == '__main__':
    main()

